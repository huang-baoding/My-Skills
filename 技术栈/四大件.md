# 1  操作系统

## 1.1  进程和线程

进程其实是应用程序在内存里完成工作的一个过程，要完成这个过程就需要分配CPU资源，进程就是操作系统进行资源分配的基本单位；而线程可以理解为一个执行流，一个进程拥有了CPU资源之后需要做很多任务，它把这些任务分为一个或多个执行流，这些执行流就是该进程内的线程，需要操作系统的调度来执行，线程是系统调度的基本单位 。 每个进程都有独立的地址空间，一个进程崩溃不影响其它进程，但是进程之间的切换开销也很大；一个进程中的多个线程共享该进程的地址空间，所以线程间切换的开销就比较小，但是一个线程的非法操作会使整个进程崩溃。总的来说多进程指的是操作系统中同时运行的多个程序而多线程指的是在同一个进程中同时运行的多个任务。

Go程序内的协程goroutine是一种用户态的轻量级的线程，比线程所占内存更小，一个goroutine大概只占用4kb的内存，一个Go程序创建几百万个goroutine是没有问题的，而且goroutine之间的切换都是由runtime管理的，处于用户态，开销更小。goroutine在用户态就可以创建，而线程需要操作系统来创建。

## 1.2  进程间通信

常见的进程间的通信方式主要有以下6种：1管道通信、2消息队列、3共享内存、4信号、5信号量、6socket。

（1）管道有匿名管道和命名管道，匿名管道在Linux中是一条竖线，只能用来在父子进程间通信，用完了就会被销毁。我们也可以用mkfifo创建命名管道，命名管道可以在不相关的进程间通信。往管道里面发送数据的进程会阻塞，直到有别的进程将数据取走，所以管道通信效率比较低，不适合进程间频繁地交换数据。【管道本质上就是内存中的缓冲区，也是一个文件，用来存放不同的进程间进行通信的数据，他有一些特点：互斥访问，写到满阻塞，读到空阻塞，没写满不可以读，没读空不可以写。】

（2）消息队列是进程间的数据交换以格式化消息为单位，存入内核中的消息链表，通过操作系统提供的原语来进行数据交换。与管道不同的是，存入消息的进程不会阻塞，存入后他就可以去坐别的事了，等到取消息的进程需要了再过来取就行。

（3）前面说的管道和消息队列都会发生用户态与内核态之间的转换，这个过程会耗费性能。而共享内存的方式可以解决这一点。

共享内存是共享一块大家可以互斥访问的内存空间，原理就是将两个进程的一部分虚拟内存映射到相同的物理块。

他又分为基于数据结构的共享和基于存储区的共享，前者限制多比如只能放数组等是一种低级通信，而后者没有这些限制、速度更快是一种高级通信。

（4）信号量

信号量其实是一个整型的计数器，主要用于实现进程间的互斥与同步。有两种可以控制信号量的原子操作，也就是PV操作。在使用共享资源之前执行P操作，表示计数器减1，归还共享资源后执行V操作，表示计数器加1。信号量初始化为1表示互斥信号量，同一时刻始终只能有一个进程可以访问。信号量初始化为0表示同步信号量。例如生产和消费问题，生产进程结束后执行V操作加1，消费进程在执行P操作后才能执行，反着来的话消费进程就会被阻塞。

（5）信号

信号是进程间唯一的一种异步通信,一般用于异常情况下的通信。进程需要为信号设置相应的监听处理，当收到特定信号时，执行相应的操作。比如在Linux中杀死和重启一个进程就是一种信号。在Go语言中主要用os包中的signal产生信号，用signal包里的Notify函数做相应的处理。

> 操作系统中，常见产生信号的方式：
>
> * 用户输入：例如ctrl+c可以发送中断信号。
> * 系统调用：例如进程执行除0等非法操作时，操作系统会产生信号告诉进程发生了错误。
> * 硬件和软件的变化也有可能会产生信号。
>
> 在Golang中可以使用channel来实现自定义的信号机制。

（6）Socket

前面都是在同一台主机上的进程间通信。实际开发中我们更多的是需要跨网络与不同主机上的进程通信，这就需要Socket通信了。我们可以通过IP加端口号的方式唯一确定需要和我们进行通信的进程。

（7）说到通信的话我们Go语言不主张用共享内存的方式来通信，而是主张用通信的方式共享内存。主要体现在通道上。

## 1.3  死锁

死锁主要是由于资源分配和并发进程推进顺序不当导致的，它的必要条件有四个：互斥、部分分配、不可抢占、循环等待。我们可以破坏它的必要条件来预防死锁，比如使资源可以被抢占等,或者通过银行家算法来判断是否处于安全状态。当已经发生死锁后我们可以采用剥夺资源、进程回滚或撤销进程的方式解除死锁。

## 1.4  CPU调度(执行进程的时候)

(1) 先来先服务

(2) 短作业优先

(3) 按优先级

(4) 时间片轮转算法

(5) 多级队列

>  按性质分为多队列，不同的队列采用不同的调度算法

(6) 多级反馈队列

>  分为多个执行队列，执行完时间片后进入下一级队列

(7) 高响应比优先  作业周转时间(等待时间+执行时间)/作业执行时间

## 1.5  什么是虚拟内存

虚拟内存是计算机系统管理内存的一种技术，他让应用程序以为自己分配到了符合自己大小的一片连续的内存，实际上他通常是被映射到多个内存碎片，还有部分在磁盘上，只有需要用到时才会被交换进入内存。也就是说虚拟内存可以只把程序运行的部分换入内存，并且充分利用每一块内存碎片，极大提高了内存的利用率。

## 1.6  内存分配

有连续内存分配（现代os已经不采用）和离散内存分配两种方式；连续分配方式有单一连续区分配（单一进程）、固定分区分配（有内碎片）和可变分区分配（最先、最佳、最坏适应法；有外碎片）；离散分配有分页，分段和段页式管理；分段主要是基于程序结构考虑的，把有不同功能的各部分分成不同的段，这些段以可变分区分配的方式放入内存。而分页主要是基于系统考虑的，将内存分为大小相同的页框，然后也再将程序分页，然后由页表将程序的分页映射到分散的页框中。现在的系统一般都采用页式管理加虚拟内存的方式来管理内存，只装入经常使用到的页，其它部分在后面运行的过程中按需装入。段页式就是两种方式的结合，先将程序按功能结构分段，再将这些段分页。

## 1.7  页面置换

(1) 理想淘汰算法

(2) 随机淘汰算法

(3) 先进先出算法

balady现象（分配的物理页面越多，缺页中断次数反而增加）

(4) 最近最久未使用页面置换算法

(5) 时钟页面置换算法（设置访问位，先进先出+跳过访问的页）

## 1.8  抖动

抖动指的就是刚被调出内存的页又要马上被调回内存， 这些调页的时间甚至大于进程执行时间，降低了CPU的利用率。

（1）防止抖动的根本手段：给进程分配足够多的物理页框

（2）那么我们怎样确定分配够了，而不用分配过多呢？

只需要使驻留集稍微大于工作集就可以使进程顺利运行，合理地解决抖动问题

（3）驻留集：在当前时刻，进程实际驻留在内存中的页集合。

（4）工作集：工作集就是指在某段时间间隔Δ 里，进程实际所要访问页面的集合。

## 1.9  文件的结构

文件的结构分为连续结构、链接结构和索引结构；连续结构现在已经不采用了，链接结构不适用与数据的随机访问，目前一般都使用多级索引结构

## 1.10  数据传输控制方式

（1）程序直接控制方式

CPU不断检查IO设备的准备情况，浪费CPU时间，而且IO准备就绪后CPU参与数据传送工作，而不能执行原程序。

（2）中断方式

CPU向IO发出命令后可以执行其他工作，当收到IO中断后转到相应的中断处理程序。

（3）DMA方式

在外围设备和内存之间开辟数据交换通路，由DMA控制器控制。需要硬件支持。

（4）通道方式

通道其实是一种特殊的执行I/O指令的处理机，控制设备与内存直接进行数据交换。 

## 1.11  缓冲技术

主要是减少对CPU的中断频率和提高CPU和IO的并行性

有专用的硬件缓冲器或者是在内存中划出一个专用缓冲区，存放输入输出的数据。

 

## 1.12  五中网络IO模型			//没看懂

(1) 阻塞IO（blocking IO）

(2) 非阻塞IO（non-blocking IO）

(3) 多路复用IO（IO multiplexing）

(4) 异步IO（Asynchronous I/O）

(5) 信号驱动IO（signal driven I/O， SIGIO）

## 1.13  并发和并行的区别

宏观上要是同时执行，在微观上的话，并行也是同时执行的，而并发是交替执行的

## 1.14  同步和异步的区别

同步是指协调多个程序顺序访问一个资源，是阻塞式的。异步是指通过缓冲区的方式通信，不用一直等待，是非阻塞式的。

我们可以拿Go语言中的Channel举例。当channel没有缓冲时，goroutine之间就是同步通信，当channel有缓冲时，goroutine之间就是异步通信。

## 1.15  常见缓存淘汰算法

（1）最不经常使用算法（LFU）

使用一个计数器来记录条目被访问的频率，淘汰计数最小的条目。

（2）最近最少使用算法（LRU）

运用队列的思想，把使用过后的条目重新放进一头，另一头就是最近没被使用的。

（3）自适应缓存替换算法(ARC)

（4）先进先出算法（FIFO）

（5）最近最常使用算法（MRU）

### 

## 线上 cpu 和内存突然飙高后应该怎么排错（debug）

## 哪些操作会导致内存泄漏

## 哪些操作会导致 io 开销大幅上升



**UDP 如何实现可靠连接？**

# 2  计算机网络

## 2.1  网络模型及其作用

**网络七层模型**

应用层			为应用提供交互服务

 表示层			数据转化

 会话层			建立或解除联系

 运输层			为不同主机的进程间的数据传输提供服务

 网络层			为数据报选择路由

 数据链路层		把IP数据报组装成帧和差错检测

 物理层			以二进制形式传输数据

**网络四层模型**

应用层

传输层

网络层

网络接口层

## 2.2  常见的网络协议

（1）应用层协议：DNS,HTTP,HTTPS,TFTP,FTP,SNMP,SMTP

**DNS**：53(端口) UDP/TCP(载体) 是将人类可读的域名 (如，www.baidu.com) 转换为机器可读的 IP 地址 (如，192.0.2.44)。

**HTTP**：80 TCP 指定了客户端可能发送给服务器什么样的消息以及得到什么样的响应。

**HTTPS**：443 HTTP的升级版，增加了传输数据的安全性，HTTPS协议是在HTTP的基础上增加了一个SSL外壳

**DHCP**：自动分配IP地址

（2）传输层协议

**UDP**：无需建立连接就可以发送封装的 IP 数据包

**TCP**：是一种面向连接、可靠的、基于字节流的传输层协议

（3）网络层  IP,ICMP,IGMP,RIP,OSPF,BGP

**IP**：寻址和路由；分片与重组

**ICMP**：放在IP数据包里 检测网络通信故障和实现链路追踪

（4）数据链路层	ARP,PPP,SLIP,CSLIP,MTU

**ARP**：负责把目的主机的IP 地址解析成目的MAC地址

## 2.3  三次握手

TCP连接都是C/S方式的，握手都是客户端主动发起的。

服务器运行之后就会处于监听（Listen）状态，客户端主动给服务器发送连接请求（IP）数据报后会进入信号已发送（SYN-sent）的状态，发送的请求数据报中，TCP首部标记位SYN=1，序号seq=x（随机）。服务器收到请求后会给客户端发回确认数据报然后进入信号已接收（SYN-rcvd）的状态，发回数据包中首部标记位SYN也是1，同时还多了一个确认为ACK为1，还有一个它自己的序号y，确认号是请求序号加1。客户端收到服务器的确认数据包后也会给服务器发送一个确认数据报，然后处于established的状态。发回确认数据报，主要是为了告诉服务器我已经受到你的确认并且处于连接状态了。发送的确认数据报中没有SYN标记位了，有确认为ACK为1，序号是请求序号加1，确认号是刚刚收到的服务器确认数据包的序号加1。服务器收到确认数据报后也进入established的状态，此时双方就可以进行数据的交互了。

> 三次握手和四次挥手都是tcp协议特有的，也有的人说http的三次握手和四次挥手，但其实http协议也是运行在tcp协议上的。

## 2.4  为什么不是两次握手

（1）实现可靠通信。双方都会有一个序号，互相进行序号的确认就保证了通信的可靠。

（2）放置重复连接。当服务器端收到过期链接请求并回应后，客户端已经不需要了，就不会进行第三次握手，也就不会建立连接。

## 2.5  四次挥手

四次挥手本质上就是我释放连接，你确认；然后再到你释放连接，我确认的过程。通信结束后双方都可以主动释放连接，我们假设是客户端释放和服务器的连接：

首先，双方都是在established的状态，客户端向服务器发送了一个释放报文段，然后进入FIN-wait状态，报文段首部标记位FIN为1，序号为u。服务器收到后发回对客户端的确认，然后进入CLOSE-wait的状态，确认报文段的确认标记位ACK为1，序号为v，确认号为刚刚请求释放报文段的序号加1（u+1）。服务器发送回第一个确认报文段后仍然可以单方向给客户端传数据，当数据都传完了之后，服务器也向客户端发送了一个释放报文段后就进入了LAST-ACK的状态，发回的释放报文段中有释放标记位FIN为1，确认标记ACK为1，它有自己的序号为w，确认号和上一次发的报文段的确认号一样。客户端收到后也会向服务器发回一个确认报文段，然后进入TIME-WAIT状态，之后在等待两倍的最大报文段生存时间就会真正释放连接，这个确认报文段中有确认位ACK为1，序号为第一次挥手的序号加1（u+1），确认号为上一次挥手的序号加1（w+1）。服务器收到这个确认数据报后就直接释放连接了。

## 2.6  为什么是四次挥手

四次挥手是两次释放连接的过程。假设是客户端不需要再向服务端发送数据了它就会发送释放报文段，服务器会回应一个确认报文段。但是还不能真正断开连接，要是服务器还有消息没有发送完怎么办，所以此时服务器仍然可以给客户端发送数据。等到发送完了，服务端也给客户端发送一个释放报文段，客户端会回应一个确认报文段，之后再等待两个最大报文段生存时间后才会真正释放连接。而服务端收到确认报文段后就直接释放连接了。

## 2.7  为什么要等待两个最大报文段生存时间

（1）保证最后一个确认报文段能够到达服务器，否则服务器收不到的话就会一直超时重发释放报文段，直到被确认。

（2）确保失效的连接请求都消失在本次连接中。

## 2.8  TCP和UDP的区别

| TCP                                | UDP                                            |
| ---------------------------------- | ---------------------------------------------- |
| TCP是面向连接的可靠传输            | UDP无连接不可靠                                |
| 面向字节流，把数据看成一连串字节流 | 面向报文                                       |
| 传输数据有序                       | 不保证数据的有序性                             |
| 首部20字节                         | 首部8字节                                      |
| 重量级协议                         | 轻量级协议                                     |
| 连接只能是一对一的（端到端）       | 支持一对一、一对多、多对一和多对多的通信方式。 |
| 有流量控制和拥塞控制               | 没有流量控制和拥塞控制                         |
| 传输速度相对较慢                   | 传输速度相对较快                               |

> TCP支持一对一是一种面向连接的可靠传输协议，保证数据有序传输，其首部为20字节并且面向字节流，同时具有流量控制和拥塞控制，但传输速度相对较慢,属于重量级协议；
>
> UDP支持一对多则是无连接不可靠的传输协议，不保证数据有序传输，其首部为8字节并且面向报文，不具备流量控制和拥塞控制，但传输速度较快,属于轻量级协议。





## 2.9  TCP如何保证可靠传输

(1) 对数据报的校验、响应、重传（举个例子）。

(2) 对失序数据包重新排序，然后丢弃重复的数据。

(3) 流量控制，主要是为了让接收方来得及接收数据。

## 2.10  流量控制和拥塞控制

拥塞控制和流量控制不同，拥塞控制是一个全局性的过程，而流量控制指点对点通信量的控制。

流量控制是为了控制发送方的发送速率，保证接收方来得及接收。TCP会话的双方分别维护一个发送窗口和一个接收窗口，接收方送回的响应报文段中有可以控制发送窗口大小的window字段。发送窗口的大小一般约等于接收窗口的大小。

拥塞控制就是为了防止过多的数据注入到网络中，防止链路过载。为了进行拥塞控制，TCP 发送方要维持一个拥塞窗口(cwnd)的状态变量。拥塞控制窗口的大小取决于网络的拥塞程度，并且动态变化。发送方让自己的发送窗口取为拥塞窗口和接收方的接受窗口中较小的一个。 

TCP的拥塞控制采用了四种算法，即：慢开始、拥塞避免、快重传和快恢复。

慢开始：逐渐增大拥塞窗口，cwnd初始值为 1，每经过一个传播轮次，cwnd 加倍。

拥塞避免：让拥塞窗口 cwnd 缓慢增大，即每经过一个往返时间 RTT 就把发送方的 cwnd 加 1。

快重传与快恢复：简称FRR是一种拥塞控制算法，它能快速恢复丢失的数据报。

**快重传与快恢复需要学习一下**

## 2.11  适合TCP、UDP的使用场景：

* TCP
  * 可靠传输（如文件下载，邮件）
  * 保证有序（比如观看电影）
  * 数据流量较大的场景，因为TCP提供了流量控制和拥塞控制（如Web应用和数据库）
* UDP
  * 时性要求高的场景：UDP没有TCP的重传机制，数据传输速度更快。（如视频电话、在线游戏等）
  * 数据量较小的场景：没有流量控制和拥塞控制机制，不会调整数据发送的速度（如DNS查询、NTP协议等）
  * 需要广播和多播的场景：可以在网络中同时向多个主机传输数据。（如视频流媒体等）

## 2.12 HTTP协议

HTTP协议建立在TCP协议之上，一般采用 TCP 的 80 端口。HTTP 协议是无状态的，同一个客户端的这次请求和上次请求是没有对应关系，对 HTTP 服务器来说，它并不知道这两个请求是否来自同一个客户端。了解决这个问题， Web 程序引入了 Session和Cookie 机制来维护连接的可持续状态。

## 2.12  HTTP和HTTPS的区别

首先最大的区别就是HTTP是明文传输，而HTTPS是HTTP的升级加密版，被加密协议封装起来，然后加密协议再运行于TCP协议之上，所以他们使用的端口是不同的，而且这个这个加密协议需要缴费使用。另外因为HTTPS传输过程需要加密和解密处理，需要消耗更多的CPU资源。

 

## 2.13  HTTP1.0 --> HTTP1.1 --> HTTP2

HTTP1.0只能保持短暂连接

HTTP1.1的TCP连接默认不关闭，可以被多个请求复用；引入管道机制，客户端可以同时发送多个请求。

HTTP2是二进制协议，数据从文本传输进化为二进制传输且对头部（Header）进行压缩，二进制更符合机器的特性所以传输性能更高，HTTP2还支持多路复用和服务端推送。

多路复用：一个连接可以发送多个请求和回应，并且可以无序

服务端推送：客户端将服务端可能需要的数据事先发送到服务端

## 2.14 session、cookie、token

http是无状态的连接，但是我们不想每次访问服务器都要输入账号密码，所以就有了session、cookie和token来让服务器保持登录状态。

首先浏览器发起一个带有账号密码的HTTP请求。服务器收到并验证成功后会设置带有账号密码信息的cookie，然后发送给浏览器，浏览器会保存起来，这样浏览器以后的每次请求只需带上这个cookie就不用输入账号密码了。但这样是不安全的，只要电脑被黑，存放在浏览器的cookie就会泄露。

然后有了新的概念session也就是会话，服务器进行账号密码验证成功后会对每个用户的会话设置一个唯一的sessionID和会话结束时间，保存在数据库里，并且将sessionID加入到发送给客户端的cookie里，再把会话结束时间设置为cookie的有效期。浏览器拿到cookie后进行保存，加入每次的连接请求中。当cookie失效后，浏览器一般会自行删除这个cookie（会话结束）。用户就得重新输入账号密码了。但当用户群体十分大时，存储大量的sessioID在服务器里会加大服务器的压力，可能会导致服务器的超载。

然后又出现了一种新的技术JWT全称JSON Web Token，浏览器输入账号密码发送给服务器，服务器验证成功后就会生成JWT，而服务器不需要保存JWT只需要保存JWT签名的密文接着把JWT发送给浏览器，可以让浏览器以cookie或者Storage的形式进行存储，这样用户每次发送请求都会把这个JWT发送给服务器，就不需要重新输入账号密码了和session很类似，只是这里的Token是存储在浏览器这边。

Token的安全性：

JWT由三部分组成：header.payload.signature。header部分声明需要用什么算法来生成签名。payload部分是一些特定的数据，比如有效期之类的。header和payload两部分会经由Base64编码，这两段编码会结合服务器保存的密码进行算法运算（header声明的算法），最终得到签名信息signature，这样一个完整的JWT就可以发送给服务器了。

session相当于会话的属性，cookie相当于传送信息的载体，Token相当一个服务器发的令牌，有它就可以访问服务器。

## 2.15  DNS过程（域名解析过程）

 我们访问某个网址的时候计算机需要先将网址解析成对应的IP地址，这个解析的过程叫做域名解析过程。

用户在浏览器中输入目标网址如www.baidu.com

--> （1）计算机先检查本地缓存和host配置文件有没有这个地址，如果有则直接返回

--> （2）向本地DNS服务器发出解析请求，本地DNS服务器查询其缓存，如果有则直接返回

--> （3）否则向根DNS服务器发出解析请求

--> （4）根DNS服务器回对应的顶级域名服务器IP地址

--> （5）本地DNS服务器向顶级域名服务器发出解析请求

--> （6）顶级域名服务器返回权威域名服务器地址

--> （7）本地DNS服务器向权威域名服务器发出解析请求

--> （8）权威域名服务器返回对应的IP地址

--> （9）本地DNS服务器将查询到的IP地址返回给计算机

## 2.16  浏览器访问www.baidu.com经历了什么

（1）浏览器向DNS服务器发出解析域名的请求；

（2）DNS服务器将"www.baidu.com"域名解析为对应的IP地址，并返回给浏览器；

（3）浏览器与百度服务器进行三次握手，建立TCP连接；

（4）浏览器发出HTTP请求报文；

（5）服务器回复HTTP响应报文；

（6）浏览器解析响应报文，渲染HTML内容，并显示在页面上；

（7）收发报文结束，执行四次挥手，释放TCP连接。

## 2.17  几种常用的序列化协议

序列化：将对象序列化为二进制形式放进字节数组里，用于网络传输、数据持久化等。

反序列化：对网络传输对象的解码，和将磁盘上的字节数组还原为原始对象。

(1) XML		适用于配置文件存储和实时数据转换

(2) JSON		适用于传输数据量相对较小的情况，可以跨防火墙

(3) Fastjson	适用于web和Android

(4) Thrift		适用于分布式系统的RPC解决方案

(5) Avro

(6) Protobuf

## 2.18  互联网是如何工作的

## 2.19  浏览器是如何运作的



 

 